#!/usr/bin/env python3
"""
generate-migration.py - Alembic migration enhancer for Eneo patterns

Enhances autogenerated Alembic migrations with Eneo-specific patterns:
- Tenant_id composite indexes
- CONCURRENTLY index creation (zero-downtime)
- Backfill templates for new columns
- Soft delete patterns

Usage:
    # 1. Run Alembic autogenerate
    uv run alembic revision --autogenerate -m "add notifications table"

    # 2. Enhance the generated migration
    python scripts/generate-migration.py enhance \\
      --file alembic/versions/abc123_add_notifications_table.py \\
      --add-tenant-indexes \\
      --use-concurrently
"""

import re
import sys
from pathlib import Path
from typing import List, Tuple, Dict
import click


class Colors:
    RED = "\033[91m"
    GREEN = "\033[92m"
    YELLOW = "\033[93m"
    BLUE = "\033[94m"
    BOLD = "\033[1m"
    END = "\033[0m"


def read_migration_file(file_path: Path) -> Tuple[str, bool]:
    """Read migration file content"""
    try:
        return file_path.read_text(encoding="utf-8"), True
    except FileNotFoundError:
        click.echo(
            f"{Colors.RED}âŒ Error: Migration file not found: {file_path}{Colors.END}",
            err=True,
        )
        return "", False
    except Exception as e:
        click.echo(f"{Colors.RED}âŒ Error reading file: {e}{Colors.END}", err=True)
        return "", False


def parse_migration_info(content: str) -> Dict[str, str]:
    """Extract migration metadata"""
    info = {}

    # Extract revision ID
    if match := re.search(r"revision = ['\"]([^'\"]+)['\"]", content):
        info["revision"] = match.group(1)

    # Extract down_revision
    if match := re.search(r"down_revision = ['\"]([^'\"]+)['\"]", content):
        info["down_revision"] = match.group(1)

    # Extract message from docstring
    if match := re.search(r'"""([^"]+)', content):
        info["message"] = match.group(1).strip()

    return info


def detect_tables_created(content: str) -> List[str]:
    """Detect tables being created in migration"""
    tables = []

    # Pattern: op.create_table("table_name"
    pattern = r'op\.create_table\(["\']([^"\']+)["\']'

    for match in re.finditer(pattern, content):
        tables.append(match.group(1))

    return tables


def detect_tenant_id_columns(content: str, table_name: str) -> bool:
    """Check if table has tenant_id column"""
    # Look for tenant_id column definition within the table
    pattern = (
        r'op\.create_table\(["\']' + re.escape(table_name) + r'["\'].*?tenant_id.*?\)'
    )
    return bool(re.search(pattern, content, re.DOTALL))


def detect_space_id_columns(content: str, table_name: str) -> bool:
    """Check if table has space_id column"""
    pattern = (
        r'op\.create_table\(["\']' + re.escape(table_name) + r'["\'].*?space_id.*?\)'
    )
    return bool(re.search(pattern, content, re.DOTALL))


def detect_existing_indexes(content: str) -> List[str]:
    """Detect existing index creation"""
    indexes = []

    # Pattern: op.create_index("index_name"
    pattern = r'op\.create_index\(["\']([^"\']+)["\']'

    for match in re.finditer(pattern, content):
        indexes.append(match.group(1))

    return indexes


def suggest_tenant_indexes(table_name: str, has_space_id: bool) -> List[str]:
    """Suggest tenant_id composite indexes"""
    suggestions = []

    if has_space_id:
        # Composite index for tenant + space queries
        suggestions.append(f"ix_{table_name}_tenant_space")
        suggestions.append(
            f"    op.create_index(\n"
            f'        "ix_{table_name}_tenant_space",\n'
            f'        "{table_name}",\n'
            f'        ["tenant_id", "space_id"]\n'
            f"    )"
        )

    # Tenant-only index
    suggestions.append(f"ix_{table_name}_tenant")
    suggestions.append(
        f"    op.create_index(\n"
        f'        "ix_{table_name}_tenant",\n'
        f'        "{table_name}",\n'
        f'        ["tenant_id"]\n'
        f"    )"
    )

    return suggestions


def generate_concurrently_pattern(
    table_name: str, index_name: str, columns: List[str]
) -> str:
    """Generate CONCURRENTLY index creation pattern"""
    column_list = ", ".join(columns)

    template = f'''
    # Create index CONCURRENTLY for zero-downtime deployment
    with op.get_context().autocommit_block():
        op.execute("""
            CREATE INDEX CONCURRENTLY IF NOT EXISTS {index_name}
            ON {table_name} ({column_list})
            WHERE deleted_at IS NULL;
        """)
'''

    return template


def generate_backfill_template(
    table_name: str, column_name: str, default_value: str
) -> str:
    """Generate backfill template for new non-nullable column"""
    template = f'''
    # Backfill {column_name} in batches
    from sqlalchemy import text

    bind = op.get_bind()
    batch_size = 5000
    rows_updated = -1

    while rows_updated != 0:
        rows_updated = bind.execute(
            text("""
                WITH cte AS (
                    SELECT id
                    FROM {table_name}
                    WHERE {column_name} IS NULL
                    LIMIT :batch_size
                )
                UPDATE {table_name} t
                SET {column_name} = :default_value
                FROM cte
                WHERE t.id = cte.id
                RETURNING t.id
            """),
            dict(batch_size=batch_size, default_value="{default_value}"),
        ).rowcount

        if rows_updated and rows_updated > 0:
            # Small sleep to reduce pressure on hot tables
            bind.execute(text("SELECT pg_sleep(0.01)"))

    # Set NOT NULL constraint after backfill
    op.alter_column("{table_name}", "{column_name}", nullable=False)
'''

    return template


@click.group()
def cli():
    """Alembic migration enhancer for Eneo patterns"""
    pass


@cli.command()
@click.option(
    "--file",
    "migration_file",
    required=True,
    help="Path to autogenerated migration file",
)
@click.option(
    "--add-tenant-indexes", is_flag=True, help="Add tenant_id composite indexes"
)
@click.option(
    "--use-concurrently", is_flag=True, help="Convert to CONCURRENTLY index creation"
)
@click.option("--dry-run", is_flag=True, help="Show suggestions without modifying file")
def enhance(migration_file, add_tenant_indexes, use_concurrently, dry_run):
    """Enhance autogenerated migration with Eneo patterns"""

    file_path = Path(migration_file)

    click.echo(
        f"{Colors.BLUE}{Colors.BOLD}ðŸ” Analyzing migration file...{Colors.END}\n"
    )

    # Read migration file
    content, ok = read_migration_file(file_path)
    if not ok:
        sys.exit(2)

    # Parse migration info
    info = parse_migration_info(content)

    click.echo(f"{Colors.BOLD}Migration Info:{Colors.END}")
    click.echo(f"  Revision: {info.get('revision', 'UNKNOWN')}")
    click.echo(f"  Down Revision: {info.get('down_revision', 'UNKNOWN')}")
    click.echo(f"  Message: {info.get('message', 'UNKNOWN')}")
    click.echo()

    # Detect tables
    tables_created = detect_tables_created(content)

    if not tables_created:
        click.echo(f"{Colors.YELLOW}âš ï¸  No tables detected in migration{Colors.END}")
        click.echo("   This might be a column addition or other operation")
        sys.exit(0)

    click.echo(f"{Colors.BOLD}Tables Created:{Colors.END}")
    for table in tables_created:
        click.echo(f"  - {table}")
    click.echo()

    # Analyze each table
    suggestions = []

    for table in tables_created:
        has_tenant_id = detect_tenant_id_columns(content, table)
        has_space_id = detect_space_id_columns(content, table)
        existing_indexes = detect_existing_indexes(content)

        click.echo(f"{Colors.BOLD}Analyzing {table}:{Colors.END}")
        click.echo(
            f"  tenant_id: {Colors.GREEN if has_tenant_id else Colors.RED}{'YES' if has_tenant_id else 'NO'}{Colors.END}"
        )
        click.echo(
            f"  space_id: {Colors.GREEN if has_space_id else Colors.YELLOW}{'YES' if has_space_id else 'NO'}{Colors.END}"
        )
        click.echo()

        # Suggest tenant indexes if missing
        if has_tenant_id and add_tenant_indexes:
            needed_index = (
                f"ix_{table}_tenant_space" if has_space_id else f"ix_{table}_tenant"
            )

            if needed_index not in "".join(existing_indexes):
                click.echo(
                    f"{Colors.YELLOW}ðŸ’¡ Suggestion: Add tenant_id composite index{Colors.END}"
                )

                if use_concurrently:
                    columns = (
                        ["tenant_id", "space_id"] if has_space_id else ["tenant_id"]
                    )
                    suggestion = generate_concurrently_pattern(
                        table, needed_index, columns
                    )
                    suggestions.append((table, "tenant_index_concurrently", suggestion))
                else:
                    index_suggestions = suggest_tenant_indexes(table, has_space_id)
                    suggestions.append((table, "tenant_index", index_suggestions[1]))

    # Display suggestions
    if suggestions:
        click.echo(
            f"\n{Colors.BOLD}{Colors.BLUE}ðŸ“ Enhancement Suggestions:{Colors.END}\n"
        )

        for table, enhancement_type, code in suggestions:
            click.echo(f"{Colors.BOLD}For table '{table}':{Colors.END}")
            click.echo(f"{Colors.GREEN}# Add to upgrade() function:{Colors.END}")
            click.echo(code)
            click.echo()

        if not dry_run:
            click.echo(
                f"{Colors.YELLOW}âš ï¸  Auto-injection not implemented yet (safety){Colors.END}"
            )
            click.echo(
                "   Please copy the code above and paste into your migration file\n"
            )
        else:
            click.echo(f"{Colors.BLUE}[DRY RUN] No files modified{Colors.END}\n")
    else:
        click.echo(
            f"{Colors.GREEN}âœ… No enhancements needed - migration looks good!{Colors.END}\n"
        )


@cli.command()
@click.option("--table", required=True, help="Table name")
@click.option("--column", required=True, help="Column name")
@click.option("--default", required=True, help="Default value for backfill")
def backfill_template(table, column, default):
    """Generate backfill template for adding non-nullable column"""

    click.echo(
        f"{Colors.BLUE}{Colors.BOLD}ðŸ“‹ Backfill Template for {table}.{column}{Colors.END}\n"
    )
    click.echo(f"{Colors.YELLOW}Add this to your upgrade() function:{Colors.END}\n")

    template = generate_backfill_template(table, column, default)
    click.echo(template)

    click.echo(f"\n{Colors.BLUE}Downgrade function:{Colors.END}\n")
    click.echo(f'''
    # Downgrade: drop column
    op.drop_column("{table}", "{column}")
''')


@cli.command()
@click.option("--table", required=True, help="Table name")
@click.option("--columns", required=True, help="Comma-separated column names")
@click.option("--name", help="Custom index name (optional)")
def index_template(table, columns, name):
    """Generate CONCURRENTLY index template"""

    column_list = [c.strip() for c in columns.split(",")]
    index_name = name or f"ix_{table}_{'_'.join(column_list)}"

    click.echo(
        f"{Colors.BLUE}{Colors.BOLD}ðŸ“‹ CONCURRENTLY Index Template{Colors.END}\n"
    )
    click.echo(f"{Colors.YELLOW}Add this to your upgrade() function:{Colors.END}\n")

    template = generate_concurrently_pattern(table, index_name, column_list)
    click.echo(template)

    click.echo(f"\n{Colors.BLUE}Downgrade function:{Colors.END}\n")
    click.echo(f'''
    # Drop index CONCURRENTLY
    with op.get_context().autocommit_block():
        op.execute("""
            DROP INDEX CONCURRENTLY IF EXISTS {index_name};
        """)
''')


@cli.command()
def patterns():
    """Show common Eneo migration patterns"""

    click.echo(
        f"{Colors.BOLD}{Colors.BLUE}ðŸŽ¯ Common Eneo Migration Patterns{Colors.END}\n"
    )

    click.echo(f"{Colors.BOLD}1. Multi-Tenant Table Creation{Colors.END}")
    click.echo("""
op.create_table(
    'notifications',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('tenant_id', sa.UUID(), nullable=False),
    sa.Column('space_id', sa.UUID(), nullable=True),

    # Your columns here
    sa.Column('title', sa.String(), nullable=False),
    sa.Column('content', sa.Text(), nullable=True),

    # Audit columns
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.func.now(), nullable=False),
    sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.func.now(), onupdate=sa.func.now(), nullable=False),
    sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True),

    # Foreign keys
    sa.ForeignKeyConstraint(['tenant_id'], ['tenants.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['space_id'], ['spaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
)

# Composite indexes for multi-tenant queries
op.create_index('ix_notifications_tenant_space', 'notifications', ['tenant_id', 'space_id'])
op.create_index('ix_notifications_tenant', 'notifications', ['tenant_id'])
""")

    click.echo(f"\n{Colors.BOLD}2. CONCURRENTLY Index (Zero-Downtime){Colors.END}")
    click.echo('''
# MUST use autocommit_block for CONCURRENTLY operations
with op.get_context().autocommit_block():
    op.execute("""
        CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_tenant_email
        ON users (tenant_id, email)
        WHERE deleted_at IS NULL;
    """)
''')

    click.echo(f"\n{Colors.BOLD}3. Add Non-Nullable Column with Backfill{Colors.END}")
    click.echo('''
# Step 1: Add column as nullable
op.add_column('users', sa.Column('status', sa.String(), nullable=True))

# Step 2: Backfill in batches
from sqlalchemy import text
bind = op.get_bind()
batch_size = 5000

rows_updated = -1
while rows_updated != 0:
    rows_updated = bind.execute(
        text("""
            WITH cte AS (
                SELECT id FROM users WHERE status IS NULL LIMIT :batch_size
            )
            UPDATE users t SET status = :default_value
            FROM cte WHERE t.id = cte.id
            RETURNING t.id
        """),
        dict(batch_size=batch_size, default_value="active"),
    ).rowcount

# Step 3: Set NOT NULL
op.alter_column('users', 'status', nullable=False)
''')

    click.echo(f"\n{Colors.BOLD}4. Soft Delete Pattern{Colors.END}")
    click.echo("""
# Add deleted_at column
op.add_column('entities', sa.Column('deleted_at', sa.DateTime(timezone=True), nullable=True))

# Optional: Index for active records queries
op.create_index('ix_entities_active', 'entities', ['tenant_id'], postgresql_where=sa.text('deleted_at IS NULL'))
""")


@cli.command()
def doctor():
    """Check Alembic environment health"""
    import subprocess

    click.echo(
        f"{Colors.BLUE}{Colors.BOLD}ðŸ¥ Alembic Environment Health Check{Colors.END}\n"
    )

    # Check for single HEAD
    try:
        result = subprocess.run(
            ["uv", "run", "alembic", "heads"],
            capture_output=True,
            text=True,
            timeout=10,
        )

        if result.returncode == 0:
            heads = [
                line.strip()
                for line in result.stdout.strip().split("\n")
                if line.strip()
            ]

            if len(heads) == 1:
                click.echo(
                    f"{Colors.GREEN}âœ“{Colors.END} Single HEAD detected: {heads[0]}"
                )
            elif len(heads) > 1:
                click.echo(
                    f"{Colors.RED}âœ—{Colors.END} Multiple HEADs detected ({len(heads)})"
                )
                click.echo(
                    f"{Colors.YELLOW}  Run: uv run alembic merge -m 'merge heads'{Colors.END}"
                )
                for head in heads:
                    click.echo(f"     - {head}")
            else:
                click.echo(f"{Colors.YELLOW}âš {Colors.END} No HEADs found")
        else:
            click.echo(f"{Colors.RED}âœ—{Colors.END} Error running alembic heads")
            click.echo(result.stderr)

    except FileNotFoundError:
        click.echo(f"{Colors.RED}âœ—{Colors.END} uv command not found")
    except subprocess.TimeoutExpired:
        click.echo(f"{Colors.RED}âœ—{Colors.END} Command timeout")

    click.echo()

    # Check for migration file count
    versions_dir = Path("backend/alembic/versions")
    if versions_dir.exists():
        py_files = list(versions_dir.glob("*.py"))
        migration_count = len([f for f in py_files if not f.name.startswith("_")])
        click.echo(f"{Colors.GREEN}âœ“{Colors.END} {migration_count} migrations found")
    else:
        click.echo(
            f"{Colors.RED}âœ—{Colors.END} Versions directory not found: {versions_dir}"
        )


if __name__ == "__main__":
    cli()
